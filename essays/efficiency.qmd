---
title: "The Power of Efficiency"
format: html
editor: visual
---

According to Wikipedia, the definition of efficiency is as follows: "Efficiency is the often measurable ability to avoid wasting materials, energy, efforts, money, and time in doing something or in producing a desired result. In a more general sense, it is the ability to do things well, successfully, and without waste." In terms of data science and statistical computing, this looks like code structured in such a way that eliminates redundancy in code structure/syntax, and follows a 'path of least resistance' to achieve the same outcomes as less efficient code would, (only, in a faster, less cluttered way.) Efficiency allows me to write code that not only makes code more clear to read to the user, but also takes up less computer storage and saves time when running the program. Efficiency is important because with it, larger programs will take minimal time to run and we can accomplish more complicated statistical analyses and not worry about breaking our code or having to wait a while to achieve results. With efficiency, essentially, we can do more in a shorter amount of time, and we can do it more cleanly and presentably. I've encountered efficiency in multiple scenarios throughout the quarter, my first big exposure that I can remember was in PA 3. Before this, I wasn't exactly sure what efficient code in R was supposed to look like. After PA 3, I had a much better idea of what I needed to do to improve the efficiency of my code. The dplyr functions in this PA provided great help in visualizing not only efficient code, (in that one dplyr function could accomplish multiple things within it, for example,) but also what tidy code looks like, and this set a precedent for me for what I needed to work towards throughout the quarter. I've had some 'aha moments' towards the end of the quarter in terms of my code becoming more efficient. An example of this is from Lab 8 with my sing_day function. Iteration is one of the most important ways to be efficient in programming as a data scientist, and I was impressed with myself that I was able to (with a lot of hard work and extra help) write a function that did what it was supposed to with efficiency and style (e.g. the glue statements were able to extract the components of the song to mash them together in reverse order with repetition of certain parts, all while being efficient!) Another 'aha' moment that I had was with Lab 9, in particular the allison table with the pivot_wider. Pivoting was another one of those concepts that took me a while to understand, but in this lab, things made sense with the pivot we had to do. Instead of, for example, creating a new data set from the old one in a separate statement, e.g. using an inefficient method, I pivoted this data set in one statement that allowed the rows to be ordered in a certain way, and simultaneously the columns are structured in their own way. Doing both of these things is efficient because of the way that they are structured within one single statement, and I am glad that I was able to figure this out for this context and understand how things structured like this are more efficient using those tools.
